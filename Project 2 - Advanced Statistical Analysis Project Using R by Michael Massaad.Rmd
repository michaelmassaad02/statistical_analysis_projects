---
title: "Project 2- Advanced Statistical Analysis Project Using R by Michael Massaad"
author: 'Michael Massaad'
date: "2024-04-02"
output: pdf_document
---
This Project aims to analyse consumer spending patterns across different regions using multiple linear regression, hypothesis testing, and model selection.

# 1. Data generation and visualization

```{r}
set.seed(123) # For reproducibility
# Generating random data
n <- 100 # Number of observations
regions <- c("North", "South", "East", "West")
spending_categories <- c("Food", "Clothing", "Electronics")
data <- data.frame(
  Region = sample(regions, n, replace = TRUE),
  Income = rnorm(n, mean = 50000, sd = 10000),
  
  Age = sample(20:70, n, replace = TRUE),
  Spending = rnorm(n, mean = 300, sd = 50),
  Category = sample(spending_categories, n, replace = TRUE)
)

dim(data)
str(data)
head(data, 10)
summary(data)
```

## 1.1 Data plots and distribution analysis

### 1.1.1 Histograms of Income, Age and Spending variables
```{r, message = FALSE, warning = FALSE}
library(patchwork)
library(ggplot2)

p1 = ggplot(data, aes(x = Income)) + geom_histogram(fill = "red", color = "black") + 
  theme_minimal() + labs(title = "Histogram of Income", x = "Income", y = "Frequency")

p2 = ggplot(data, aes(x = Age)) + geom_histogram(fill = "lightgreen", color = "black") + 
  theme_minimal() + labs(title = "Histogram of Age", x = "Age", y = "Frequency")

p3 = ggplot(data, aes(x = Spending)) + geom_histogram(fill = "gray", color = "black") + 
  theme_minimal() + labs(title = "Histogram of Spending", x = "Spending", y = "Frequency")

p1 | p2 | p3

```

In observing all the histograms, we can observe that the histogram for the Income is approximately symmetric, the histogram for the Age is also approximately symmetric (since the distribution on both the right and the left is approximately equal), the histogram for the Spending is approximately symmetric (since we can observe that most of the data is distributed in the center of the graph).

### 1.1.2 Bar chart for the Region and Category variables
```{r}
bc1 = ggplot(data, aes(x = Region)) + geom_bar(fill = "purple", color = "black") + 
  theme_minimal() + labs(title = "Bar Chart of Region", x = "Region", y = "Count")

bc2 = ggplot(data, aes(x = Category)) + geom_bar(fill = "blue", color = "black") + 
  theme_minimal() + labs(title = "Bar Chart of Category", x = "Region", y = "Count")

bc1 | bc2

```


### 1.1.3 Boxplots for the Income, Age, and Spending variables
```{r, message = FALSE, warning = FALSE}
library(patchwork)
library(ggplot2)

b1 = ggplot(data, aes(y = Income)) +
  geom_boxplot(
    fill = "orange",
    color = "black",
    outlier.color = "red"
  ) + theme_minimal() + labs(title = "Box Plot of Income", y = "Income")

b2 = ggplot(data, aes(y = Age)) +
  geom_boxplot(
    fill = "royalblue",
    color = "black",
    outlier.color = "red"
  ) + theme_minimal() + labs(title = "Box Plot of Age", y = "Age")

b3 = ggplot(data, aes(y = Spending)) +
  geom_boxplot(
    fill = "violet",
    color = "black",
    outlier.color = "red"
  ) + theme_minimal() + labs(title = "Box Plot of Spending", y = "Spending")

b1 | b2 | b3

```
## 1.2 Is it normally distributed?

In observing the boxplots for the Income, Age and Spending variables, we can observe that there are no outliers for any of the variables. Also, from observing the histograms and the boxplots of all 3 variables, we can conclude that they are all normally distributed which can be deduced from all 3 histograms being approximately symmetric, and which can also be reflected in the boxplots, where the mean (represented within the colored square in each plot), is approximately in the center of each distribution. Another indicator that the Income and Spending variables are normally distributed is the fact that they are generated by the rnorm command in the supplied code.

## 1.3 Is there a difference in average expenditure across any pairs of categories?

Before doing the two sided test for the equality of the means, we need to know if the variances are equal or not to use the right formula. In observing the histogram of the category variable, we can observe that it is approximately symmetric, therefore it is normally distributed. As seen in the previous questions, we know that the Spending variable is normally distributed. Therefore, both variables that will be used, being the category and spending variables, they meet the assumptions to proceed with the testing for variance equality.

### 1.3.1 Test hypothesis for the equality of means between the food and clothing category

$H_0 : mu_{foodSpending} = mu_{clothingSpending}$
$H_1 : mu_{foodSpending}$ is different from $mu_{clothingSpending}$

1. F-test for variance equality of food and clothing
```{r}
foodSpending = data$Spending[data$Category == 'Food']
clothingSpending = data$Spending[data$Category == 'Clothing']
var.test(foodSpending, clothingSpending)
```
The p-value of the F-test is $p = 0.06822$ which is greater than the significance level 0.05. Therefore, we can conclude that there isn't any significant difference in the variances, therefore we will use the t-test with the pooled variances (var.equal=TRUE).

2. t-test between food and clothing
```{r}
foodSpending = data$Spending[data$Category == 'Food']
clothingSpending = data$Spending[data$Category == 'Clothing']

t.test(foodSpending, clothingSpending, var.equal = TRUE)
```
In observing the p-value, which is $p = 0.1703 > 0.05$, we do not reject the null hypothesis, therefore the means/average expenditure of the Food and Clothing category are not different.


### 1.3.2 Test hypothesis for the equality of means between the clothing and electronics category

$H_0 : mu_{electronicsSpending} = mu_{clothingSpending}$
$H_1 : mu_{electronicsSpending}$ is different from $mu_{clothingSpending}$

1. F-test for variance equality of clothing and electronics
```{r}
electronicsSpending = data$Spending[data$Category == 'Electronics']
var.test(clothingSpending, electronicsSpending)
```
The p-value of the F-test is $p = 0.9477$ which is greater than the significance level 0.05. Therefore, we can conclude that there isn't any significant difference in the variances, therefore we will use the t-test with the pooled variances (var.equal=TRUE).

2. t-test between clothing and electronics
```{r}
t.test(clothingSpending, electronicsSpending, var.equal = TRUE)
```
In observing the p-value, which is $p = 0.5022 > 0.05$, we do not reject the null hypothesis, therefore the means/average expenditure of the Clothing and Electronics category are not different.

### 1.3.3 Test hypothesis for the equality of means between the food and electronics category

$H_0 : mu_{electronicsSpending} = mu_{foodSpending}$
$H_1 : mu_{electronicsSpending}$ is different from $mu_{foodSpending}$

1. F-test for variance equality of food and electronics
```{r}
var.test(foodSpending, electronicsSpending)
```
The p-value of the F-test is $p = 0.0646$ which is greater than the significance level 0.05. Therefore, we can conclude that there isn't any significant difference in the variances, therefore we will use the t-test with the pooled variances (var.equal=TRUE).

2. t-test between food and electronics
```{r}
t.test(foodSpending, electronicsSpending, var.equal = TRUE)
```
In observing the p-value, which is $p = 0.4839 > 0.05$, we do not reject the null hypothesis, therefore the means/average expenditure of the Food and Electronics category are not different.

### Conclusion

Through our results for the tests between category pairs, we are able to conclude that there is no difference in average expenditure between the categories.

# 2. Multiple Linear Regression and Analysis

## Getting dataset and description of dataset
```{r}
library(readxl)
dataset = read_excel("sat.xls")
dim(dataset)
str(dataset)
head(dataset, 10)
summary(dataset)
```

## Questions
1. Perform the multiple linear regression usig all the predictors and interpret the output;
```{r}
model = lm(univ_GPA ~ high_GPA + math_SAT + verb_SAT + comp_GPA, dataset)
summary(model)
model
```
In observing the summary of the model, we can observe that the $R^2_{adjusted}$ = 0.8846, which indicates that the model is a good fit for the data. In addition, we can observe that the intercept is 0.5595710, the coefficient of the high_GPA is 0.0720545, the coefficient of the mat_SAT is -0.0007338, the coefficient of the verb_SAT is 0.0008045, and the the coefficient of the comp_GPA is 0.7568120. Therefore we have the multiple linear regression model being : $\hat Y = univ_GPA = 0.0720545*(high_GPA) + -0.0007338*(mat_SAT) + 0.0008045*(verb_SAT) +  0.7568120*(comp_GPA) + 0.5595710$. Looking at the residuals from the summary, we can see that they are approximately symmetrical (small difference between the absolute values of each side), which means that the model is also approximately symmetrical. In observing the values of the coefficients, we can see that they are very small, therefore the high_GPA, mat_SAT, verb_SAT and comp_GPA variables do not  have a major impact on the univ_GPA. However, in observing the p-values of each coefficient, only the coefficient of the comp_GPA is statistically significant (i.e p<0.001), which indicates that all the work is being done by the comp_GPA variable, which can be confirmed by the fact that the coefficient for that variable is relatively large compared to the coefficients of the other variables.

2. Test the hypothesis H0 : B2 (mat_SAT) = 0 versus H1: B2 is not equal 0;

In observing the p-value of the mat_SAT coefficient, we can see that 0.19537 > alpha = 0.05, we fail to reject our null hypothesis, so the coefficient is 0. Therefore the predictor B2 doesn't contribute to the response variable Y = univ_GPA.

3. Is University GPA Linearly Related to High School GPA?
```{r}
HS_model = lm(univ_GPA ~ high_GPA, dataset)
summary(HS_model)
```
In observing the summary of the model, we have the simple linear regression: $\hat Y = univ_GPA = 0.67483*(high_GPA) + 1.09682$. In addition, we can observe that both the intercept and the high_GPA coefficient are statistically significant (i.e p<0.001). In observing the $R^2_{adjusted}$ = 0.6039, we can observe that the model is not a good representation of the response variable, therefore we can conclude that the High School GPA variable is not linearly related to the University GPA.

4. Select the best model using stepAIC function from the MASS library;

```{r}
library(MASS)
selectedModel = stepAIC(model)
summary(selectedModel)
```
Using the stepAIC, we have the best model being: $\hat Y = univ_GPA = 0.0006057*(verb_SAT) + 0.7770930*(comp_GPA) + 1.09682$.

5. Compare the selected model (obtained from 3.) and the full model (ie. with all the predictors) using adjusted R^2 and AIC;

```{r}
AIC(model, HS_model)
```
In observing the summaries of both models, we can see that the adjusted R^2 for the full model is 0.8846 and the one for the selected model is 0.6039, which is worse than the adjusted R^2 for the full model. In observing the results from the AIC, we can observe that the full model has a smaller value of AIC than the HS_model.

6. Perform all the steps of model adequacy of the selected model (HS_model obtained in question 3).
6.1 QQplot
```{r}
qq = ggplot(HS_model, aes(sample = rstandard(model))) + geom_qq() + stat_qq_line() + 
  labs(title = "Normality of residuals", x = "Theoretical Quantiles", 
       y = "Sample Quantiles")
qq
```
In observing the QQplot of the residuals, since most of the points are on/around the line, we can conclude that the assumption of the normality of the residuals is confirmed.

6.2 Residual plot
```{r}
rp = ggplot(HS_model, aes(.fitted, .resid)) + geom_point() + geom_hline(yintercept = 0, 
color = "pink") + labs(title = "Fitted versus Residuals", x = "Fitted", y = "Residuals")
rp
```
In observing the fitted versus residuals plot, we can see that the point are not evenly spread, and they form the shape of a funnel, therefore we can conclude that the variance is not constant, so the selected model does not satisfy one of the assumptions, therefore we can conclude that this is not a good model. This can also be supported by the value of the $R^2_{adjusted}$ for the model obtained in question 3 being low (with a value of 0.6039).


